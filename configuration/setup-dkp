#!/bin/bash

export CLUSTER_NAME="pega-cluster"
export CONTROL_PLANE_1_ADDRESS="10.0.0.20"
export CONTROL_PLANE_2_ADDRESS="10.0.0.21"
export CONTROL_PLANE_3_ADDRESS="10.0.0.22"
export WORKER_1_ADDRESS="10.0.0.30"
export WORKER_2_ADDRESS="10.0.0.31"
export WORKER_3_ADDRESS="10.0.0.32"
export WORKER_4_ADDRESS="10.0.0.33"
export SSH_USER=$USER
export SSH_PRIVATE_KEY_SECRET_NAME="$CLUSTER_NAME-ssh-key"

sudo systemctl restart docker
#sudo tar -xvf dkp.tar.gz
#sudo tar -xvf kommander.tar.gz
sudo mv /tmp/dkp /usr/local/bin/dkp
sudo chmod +x /usr/local/bin/dkp
sudo mv /tmp/kommander /usr/local/bin/kommander
sudo chmod +x /usr/local/bin/kommander
alias k=kubectl

dkp create bootstrap

kubectl create secret generic $CLUSTER_NAME-ssh-key --from-file=ssh-privatekey=/home/$USER/.ssh/pega
kubectl label secret $CLUSTER_NAME-ssh-key clusterctl.cluster.x-k8s.io/move=

cat <<EOF > preprovisioned_inventory.yaml
---
apiVersion: infrastructure.cluster.konvoy.d2iq.io/v1alpha1
kind: PreprovisionedInventory
metadata:
  name: $CLUSTER_NAME-control-plane
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: $CLUSTER_NAME
    clusterctl.cluster.x-k8s.io/move: ""
spec:
  hosts:
    # Create as many of these as needed to match your infrastructure
    - address: $CONTROL_PLANE_1_ADDRESS
    - address: $CONTROL_PLANE_2_ADDRESS
    - address: $CONTROL_PLANE_3_ADDRESS
  sshConfig:
    port: 22
    # This is the username used to connect to your infrastructure. This user must be root or
    # have the ability to use sudo without a password
    user: $SSH_USER
    privateKeyRef:
      # This is the name of the secret you created in the previous step. It must exist in the same
      # namespace as this inventory object.
      name: $SSH_PRIVATE_KEY_SECRET_NAME
      namespace: default
---
apiVersion: infrastructure.cluster.konvoy.d2iq.io/v1alpha1
kind: PreprovisionedInventory
metadata:
  name: $CLUSTER_NAME-md-0
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: $CLUSTER_NAME
    clusterctl.cluster.x-k8s.io/move: ""
spec:
  hosts:
    - address: $WORKER_1_ADDRESS
    - address: $WORKER_2_ADDRESS
    - address: $WORKER_3_ADDRESS
    - address: $WORKER_4_ADDRESS
  sshConfig:
    port: 22
    user: $SSH_USER
    privateKeyRef:
      name: $SSH_PRIVATE_KEY_SECRET_NAME
      namespace: default
EOF

envsubst < preprovisioned_inventory.yaml | kubectl apply -f -

dkp create cluster preprovisioned \
--cluster-name ${CLUSTER_NAME} \
--control-plane-endpoint-host $CONTROL_PLANE_1_ADDRESS \
--dry-run \
-o yaml > $CLUSTER_NAME.yaml

# sed -i 's/cloud-provider\:\ \"\"/cloud-provider\:\ \"gce\"/' $CLUSTER_NAME.yaml
# sed -i 's/konvoy.d2iq.io\/provider\:\ preprovisioned/konvoy.d2iq.io\/provider\:\ gcp/' $CLUSTER_NAME.yaml




kubectl apply -f $CLUSTER_NAME
exit 0

#### Wait for nodes ####
echo "Waiting for all nodes to come up"
while [ $(kubectl get nodes | grep Ready | wc -l) -lt 1 ]; do
  echo "Waiting for the control plane"
  sleep 30
done

# Get the kubeconfig and transfer to the cluster
dkp get kubeconfig -c ${CLUSTER_NAME} > ${CLUSTER_NAME}.conf
# Check our konvoy nodes
sleep 30
echo "Waiting for all nodes to come up"k
while [ $(kubectl get nodes --kubeconfig ${CLUSTER_NAME}.conf | grep Ready | wc -l) -lt  $(kubectl get nodes --kubeconfig ${CLUSTER_NAME}.conf | wc -l)]; do
  echo "Waiting for all nodes to come up. Currently $(kubectl get nodes --kubeconfig ${CLUSTER_NAME}.conf | grep Ready | wc -l) of $(kubectl get nodes --kubeconfig ${CLUSTER_NAME}.conf | wc -l)."
  sleep 30
done
echo "All nodes are up"
sleep 30

echo "Transferring bootstrap controllers"
dkp create bootstrap controllers --kubeconfig ${CLUSTER_NAME}.conf
dkp move --to-kubeconfig ${CLUSTER_NAME}.conf
export KUBECONFIG=$PWD/$CLUSTER_NAME.conf

# Install Load Balancer
kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e "s/strictARP: false/strictARP: true/" | \
kubectl apply -f - -n kube-system
kubectl create configmap --namespace kube-system kubevip --from-literal range-global=10.0.0.100-10.0.0.110
kubectl apply -f https://kube-vip.io/manifests/controller.yaml
kubectl apply -f https://kube-vip.io/manifests/rbac.yaml

# Build and apply kubevip manifest

alias kube-vip="docker run --network host --rm plndr/kube-vip:v0.3.5"
kube-vip manifest daemonset --services --taint --inCluster --arp --interface eth0 --leaderElection  --controlplane | kubectl apply -f -






## Kommander Install

sleep 15
kommander install --init > kommander.yaml
sed -i "4i\ \ metallb:\n    values: |\n      configInline:\n        address-pools:\n          - name: default\n            protocol: layer2\n            addresses:\n              - 10.0.0.100-10.0.0.125" kommander.yaml
kommander install --config kommander.yaml

#### Wait for helm releases
sleep 30
declare -i COMPCOUNT=0
declare -i COMPREADY=0
while [[ $COMPREADY -lt $COMPCOUNT || $COMPCOUNT -lt 30 ]]; do
  clear
  kubectl get helmreleases -n kommander 
  sleep 5
done

kubectl -n kommander get svc kommander-traefik -o go-template='https://{{with index .status.loadBalancer.ingress 0}}{{or .hostname .ip}}{{end}}/dkp/kommander/dashboard{{ "\n"}}'
kubectl -n kommander get secret dkp-credentials -o go-template='Username: {{.data.username|base64decode}}{{ "\n"}}Password: {{.data.password|base64decode}}{{ "\n"}}'
