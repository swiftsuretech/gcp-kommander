#!/bin/bash

export CLUSTER_NAME="pega-cluster"
export CONTROL_PLANE_1_ADDRESS="10.0.0.20"
export CONTROL_PLANE_2_ADDRESS="10.0.0.21"
export CONTROL_PLANE_3_ADDRESS="10.0.0.22"
export WORKER_1_ADDRESS="10.0.0.30"
export WORKER_2_ADDRESS="10.0.0.31"
export WORKER_3_ADDRESS="10.0.0.32"
export WORKER_4_ADDRESS="10.0.0.33"
export SSH_USER="dswhitehouse"
export SSH_PRIVATE_KEY_SECRET_NAME="$CLUSTER_NAME-ssh-key"

sudo systemctl restart docker
sudo mv /tmp/dkp /usr/local/bin/dkp
sudo chmod +x /usr/local/bin/dkp
sudo mv /tmp/kommander /usr/local/bin/kommander
sudo chmod +x /usr/local/bin/kommander
alias k=kubectl

dkp create bootstrap

kubectl create secret generic $CLUSTER_NAME-ssh-key --from-file=ssh-privatekey=/home/dswhitehouse/.ssh/pega
kubectl label secret $CLUSTER_NAME-ssh-key clusterctl.cluster.x-k8s.io/move=

cat <<EOF > preprovisioned_inventory.yaml
---
apiVersion: infrastructure.cluster.konvoy.d2iq.io/v1alpha1
kind: PreprovisionedInventory
metadata:
  name: $CLUSTER_NAME-control-plane
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: $CLUSTER_NAME
    clusterctl.cluster.x-k8s.io/move: ""
spec:
  hosts:
    # Create as many of these as needed to match your infrastructure
    - address: $CONTROL_PLANE_1_ADDRESS
    - address: $CONTROL_PLANE_2_ADDRESS
    - address: $CONTROL_PLANE_3_ADDRESS
  sshConfig:
    port: 22
    # This is the username used to connect to your infrastructure. This user must be root or
    # have the ability to use sudo without a password
    user: $SSH_USER
    privateKeyRef:
      # This is the name of the secret you created in the previous step. It must exist in the same
      # namespace as this inventory object.
      name: $SSH_PRIVATE_KEY_SECRET_NAME
      namespace: default
---
apiVersion: infrastructure.cluster.konvoy.d2iq.io/v1alpha1
kind: PreprovisionedInventory
metadata:
  name: $CLUSTER_NAME-md-0
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: $CLUSTER_NAME
    clusterctl.cluster.x-k8s.io/move: ""
spec:
  hosts:
    - address: $WORKER_1_ADDRESS
    - address: $WORKER_2_ADDRESS
    - address: $WORKER_3_ADDRESS
    - address: $WORKER_4_ADDRESS
  sshConfig:
    port: 22
    user: $SSH_USER
    privateKeyRef:
      name: $SSH_PRIVATE_KEY_SECRET_NAME
      namespace: default
EOF

envsubst < preprovisioned_inventory.yaml | kubectl apply -f -

dkp create cluster preprovisioned \
--cluster-name ${CLUSTER_NAME} \
--control-plane-endpoint-host $CONTROL_PLANE_1_ADDRESS


#### Wait for nodes ####
# Check our konvoy nodes
echo "Waiting for all nodes to come up"
while [ $(kubectl get nodes | grep Ready | wc -l) -lt 4 ]; do
  echo "Waiting for all nodes to come up. Currently $(kubectl --kubeconfig=admin.conf get nodes | grep Ready | wc -l) of 4."
  sleep 30
done

# Get the kubeconfig and transfer to the cluster
dkp get kubeconfig -c ${CLUSTER_NAME} > ${CLUSTER_NAME}.conf
dkp create bootstrap controllers --kubeconfig ${CLUSTER_NAME}.conf
dkp move --to-kubeconfig ${CLUSTER_NAME}.conf
export KUBECONFIG=$pwd/$CLUSTER_NAME.conf


kommander install --init > kommander.yaml
sed -i "4i\ \ metallb:\n    values: |\n      configInline:\n        address-pools:\n          - name: default\n            protocol: layer2\n            addresses:\n              - 10.0.0.100-10.0.0.125" kommander.yaml
kommander install --config kommander.yaml


#### Wait for helm releases
sleep 30
declare -i COMPCOUNT=0
declare -i COMPREADY=0
while [[ $COMPREADY -lt $COMPCOUNT || $COMPCOUNT -lt 30 ]]; do
  COMPCOUNT=$(kubectl get helmreleases -n kommander | wc -l)-1   
  COMPREADY=$(kubectl get helmreleases -n kommander | grep True | wc -l )
  echo "$COMPREADY of $COMPCOUNT have completed"
  sleep 15
done

kubectl -n kommander get svc kommander-traefik -o go-template='https://{{with index .status.loadBalancer.ingress 0}}{{or .hostname .ip}}{{end}}/dkp/kommander/dashboard{{ "\n"}}'
kubectl -n kommander get secret dkp-credentials -o go-template='Username: {{.data.username|base64decode}}{{ "\n"}}Password: {{.data.password|base64decode}}{{ "\n"}}'
